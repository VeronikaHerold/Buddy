1. cd C:\Users\veroh\OneDrive\Desktop\MMCI
2. venv\Scripts\activate
3. python main.py

git status
git init
git add <dateiname>
git commit -m "Beschreibung der Änderung"
git push



- ner processing funktioniert??
- Regex Leerzeile ignorieren
- Feedback detaillierter






MMCI/
   config/
      config.json
   data/
      GDV/
      GDV_training_data.json
   feedback_data.json
   models/
      gpt2/
         responses.py
   ner_processing.py
   training/
      buddy_mody.py
      feedback.py
      fine_tune.py
      training.py
main.py
requirements.txt
.gitignore

code folgt jetzt:

config.json:
{
    "model_name": "gpt2",
    "train_epochs": 3,
    "batch_size": 2
  }  
GDV_training_data.json:
[
    "Nice"
]
feedback_data.json:
[
    {
        "input": "Was ist GDV",
        "output": "Graphische Datenverarbeitung",
        "similarity": 1.0,
        "reward": 5
    }
]
responses.py:
import torch
import json
from transformers import GPT2LMHeadModel, GPT2Tokenizer
# In responses.py
from models.ner_processing import extract_entities

def generate_response_with_ner(prompt):
    """
    Generiert eine Antwort unter Verwendung von NER.
    """
    entities = extract_entities(prompt)
    # Hier kannst du die extrahierten Entitäten nutzen, um die Antwort zu verbessern oder anzupassen
    # Beispiel: Eine spezielle Antwort generieren, wenn eine bestimmte Entität erkannt wird
    response = "Eine spezielle Antwort für " + entities[0][0]
    return response

# Modell und Tokenizer initialisieren
with open("config/config.json", "r") as config_file:
    config = json.load(config_file)

model_name = config["model_name"]
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model.eval()

# Funktion zur Generierung von Antworten
def generate_response(prompt):
    inputs = tokenizer.encode(prompt, return_tensors="pt")
    outputs = model.generate(inputs, max_length=100, do_sample=True, top_p=0.95, top_k=60)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response
ner_processing.py:
# ner_processing.py
import spacy

# Laden des vortrainierten SpaCy-Modells für NER (z.B. "de_core_news_sm" für Deutsch)
nlp = spacy.load("de_core_news_sm")

def extract_entities(text):
    """
    Extrahiert benannte Entitäten aus dem gegebenen Text.
    """
    doc = nlp(text)
    entities = []
    for ent in doc.ents:
        entities.append((ent.text, ent.label_))
    return entities


buddy_mode.py:
import random
import difflib
import json
import re

def buddy_mode(training_data_file="data/{}/training_data.json", theme=""):
    """
    Buddy-Mode mit zwei Modi: 'Fragen' und 'Test'.
    Im Fragen-Modus stellt die KI Fragen und gibt Feedback.
    Im Test-Modus bekommt der Benutzer Multiple-Choice-Fragen, die bewertet werden.
    """
    try:
        with open(training_data_file, "r", encoding="utf-8") as file:
            training_data = json.load(file)
    except FileNotFoundError:
        print(f"Keine Trainingsdaten in {training_data_file} gefunden.")
        return

    while True:
        mode = input("Wähle den Modus ('fragen', 'test', 'exit'): ").lower()

        if mode == 'exit':
            print("Buddy-Mode beendet.")
            break
        elif mode == 'fragen':
            fragen_modus(training_data, theme)
        elif mode == 'test':
            test_modus(training_data, theme)
        else:
            print("Ungültige Eingabe. Bitte wähle 'fragen', 'test' oder 'exit'.")


def fragen_modus(training_data, theme):
    """Stellt dem Benutzer Fragen und gibt Feedback basierend auf der Antwortähnlichkeit."""
    from training.feedback import save_feedback
    while True:
        question_entry = random.choice(training_data)
        question = question_entry["input"]
        correct_answer = question_entry["output"]

        print(f"Frage: {question}")
        user_answer = input("Deine Antwort (oder 'hint' für einen Tipp, 'exit' zum Beenden): ").strip()

        if user_answer.lower() == 'exit':
            print("Fragen-Modus beendet.")
            break

        if user_answer.lower() == 'hint':
            print(f"Tipp: Die Antwort beginnt mit: {correct_answer[0]}")
            continue

        if normalize_text(user_answer) == normalize_text(correct_answer):
            print("Deine Antwort ist korrekt!")
        else:
            print(f"Leider falsch. Die richtige Antwort wäre: {correct_answer}")

        while True:
            feedback = input("Wie bewertest du die Antwort? (1 = schlecht, 5 = perfekt): ")
            if feedback in {'1', '2', '3', '4', '5'}:
                feedback = int(feedback)
                break
            else:
                print("Ungültige Eingabe. Bitte gib eine Zahl zwischen 1 und 5 ein.")
        entry = {"input": question, "output": correct_answer, "reward": feedback}
        save_feedback(entry, theme)

def test_modus(training_data, theme):
    """Der Test-Modus stellt dem Benutzer Single- und Multiple-Choice-Fragen."""
    score = 0
    total_fragen = len(training_data)

    print(f"Test für das Thema: {theme}")

    for frage_entry in training_data:
        frage = frage_entry["input"]
        korrekt_antworten = frage_entry["output"].split(', ')
        print(f"\nFrage: {frage}")

        antwort_optionen = generate_answer_options(korrekt_antworten)
        for idx, option in enumerate(antwort_optionen, start=1):
            print(f"{idx}) {option}")

        user_antworten = input("Gib die richtigen Antwortnummern ein (z.B. '1' oder '1,2'): ").split(',')

        user_antworten = [antwort_optionen[int(num.strip()) - 1] for num in user_antworten]

        if set(user_antworten) == set(korrekt_antworten):
            print("Richtig!")
            score += 1
        else:
            print(f"Leider falsch. Die richtige(n) Antwort(en): {', '.join(korrekt_antworten)}")

    print(f"\nTest beendet! Du hast {score} von {total_fragen} Fragen richtig beantwortet.")
    note = calculate_grade(score, total_fragen)
    print(f"Deine Note: {note}")

def generate_answer_options(korrekt_antworten):
    """Erzeugt Antwortoptionen inklusive der korrekten Antworten."""
    alle_antworten = set(korrekt_antworten + ["Falsch1", "Falsch2", "Falsch3"])
    return list(alle_antworten)

def calculate_grade(score, total_fragen):
    """Berechnet die Note basierend auf dem Ergebnis des Tests."""
    prozent = (score / total_fragen) * 100
    if prozent >= 90:
        return "1"
    elif prozent >= 80:
        return "2"
    elif prozent >= 70:
        return "3"
    elif prozent >= 60:
        return "4"
    else:
        return "5"

def normalize_text(text):
    return re.sub(r'\s+', ' ', text.strip().lower())

feedback.py:
import os
import json
import random
import difflib
import random
from nltk.corpus import wordnet
from models.ner_processing import extract_entities


def analyze_feedback_with_ner(feedback_text):
    """
    Analysiert das Feedback unter Verwendung von NER.
    """
    entities = extract_entities(feedback_text)
    # Hier könntest du die extrahierten Entitäten weiter verarbeiten oder analysieren
    return entities

def archive_feedback(filename="data/feedback_data.json", archive_filename="data/feedback_archive.json", max_entries=100):
    """
    Archiviert ältere Feedback-Daten, wenn die Datei eine bestimmte Größe überschreitet.
    """
    if os.path.exists(filename) and os.stat(filename).st_size > 0:
        with open(filename, "r", encoding="utf-8") as file:
            data = json.load(file)
        
        # Prüfen, ob die Anzahl der Einträge das Limit überschreitet
        if len(data) > max_entries:
            archive_data = []
            
            # Wenn es bereits archivierte Daten gibt, diese laden
            if os.path.exists(archive_filename):
                with open(archive_filename, "r", encoding="utf-8") as archive_file:
                    archive_data = json.load(archive_file)
            
            # Älteste Einträge archivieren
            archive_data.extend(data[:len(data) - max_entries])
            with open(archive_filename, "w", encoding="utf-8") as archive_file:
                json.dump(archive_data, archive_file, indent=4, ensure_ascii=False)
            
            # Feedback-Datei kürzen
            with open(filename, "w", encoding="utf-8") as file:
                json.dump(data[-max_entries:], file, indent=4, ensure_ascii=False)

            print(f"Feedback archiviert. Ältere Daten in {archive_filename} verschoben.")
            
def save_feedback(entry, theme, filename_format="data/{}/{}_feedback_data.json"):
    """
    Speichert das Feedback themenspezifisch und archiviert ältere Daten.
    """
    feedback_file_path = filename_format.format(theme, theme)

    archive_feedback(feedback_file_path)  # Feedback archivieren, falls nötig

    try:
        if os.path.exists(feedback_file_path) and os.stat(feedback_file_path).st_size > 0:
            with open(feedback_file_path, "r+", encoding="utf-8") as file:
                data = json.load(file)
                data.append(entry)
                file.seek(0)
                json.dump(data, file, indent=4, ensure_ascii=False)
        else:
            with open(feedback_file_path, "w", encoding="utf-8") as file:
                json.dump([entry], file, indent=4, ensure_ascii=False)

        print(f"Feedback in {feedback_file_path} gespeichert!")

    except json.JSONDecodeError:
        print(f"Ungültige Daten in {feedback_file_path}. Datei wird neu erstellt.")
        with open(feedback_file_path, "w", encoding="utf-8") as file:
            json.dump([entry], file, indent=4, ensure_ascii=False)

    except Exception as e:
        print(f"Fehler beim Speichern des Feedbacks: {e}")


def augment_with_synonyms(text):
    """
    Ersetzt zufällige Wörter durch Synonyme, um das Training zu erweitern.
    """
    words = text.split()
    new_text = []
    
    for word in words:
        synonyms = wordnet.synsets(word)
        if synonyms:
            synonym = random.choice(synonyms).lemmas()[0].name()
            new_text.append(synonym)
        else:
            new_text.append(word)
    
    return " ".join(new_text)

def load_feedback_data(filepath="data/feedback_data.json"):
    try:
        with open(filepath, "r") as feedback_file:
            feedback_data = json.load(feedback_file)
        return feedback_data
    except FileNotFoundError:
        print(f"Feedback-Datei {filepath} nicht gefunden.")
        return []
    
# Augmentierung während der Datenaufbereitung in prepare_data_with_feedback:
def prepare_data_with_feedback(training_data_file="data/training_data.json", feedback_file="data/feedback_data.json"):
    """
    Bereitet Trainingsdaten vor und kombiniert sie mit Feedback-Daten. 
    Falls keine Dateien vorhanden sind, werden Standardfragen verwendet. 
    Außerdem wird eine Datenaugmentierung durch Synonym-Ersetzungen durchgeführt.
    """
    # Standarddaten, falls keine Trainingsdaten vorhanden sind
    default_training_data = [
        {"input": "Was ist das Kreuzprodukt?", "output": "A X B - Die beiden Vektoren definieren ein Parallelogramm."}
    ]
    
    # Versuche, die Trainingsdaten zu laden, oder verwende Standarddaten
    try:
        with open(training_data_file, "r", encoding="utf-8") as file:
            training_data = json.load(file)
    except FileNotFoundError:
        print(f"Keine Trainingsdaten gefunden. Standardfragen werden genutzt.")
        training_data = default_training_data

    # Versuche, Feedbackdaten zu laden, oder verwende eine leere Liste
    try:
        with open(feedback_file, "r", encoding="utf-8") as file:
            feedback_data = json.load(file)
    except FileNotFoundError:
        print(f"Keine Feedbackdaten gefunden.")
        feedback_data = []

    # Kombiniere Trainingsdaten mit Feedback-Daten
    combined_data = training_data + feedback_data

    # Augmentiere Daten durch Synonym-Ersetzungen
    augmented_data = []
    for entry in combined_data:
        augmented_data.append(entry)
        augmented_entry = {
            "input": augment_with_synonyms(entry["input"]),
            "output": entry["output"]
        }
        augmented_data.append(augmented_entry)

    return augmented_data

  fine_tune.py:
import json
import torch
from transformers import Trainer, TrainingArguments
from models.gpt2.responses import model, tokenizer
from training.feedback import prepare_data_with_feedback, load_feedback_data
from torch.utils.data import Dataset

class CustomFeedbackDataset(Dataset):
    def __init__(self, feedback_data, tokenizer, max_length=512):
        self.feedback_data = feedback_data
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.feedback_data)

    def __getitem__(self, idx):
        item = self.feedback_data[idx]
        input_text = item['input']
        output_text = item['output']
        feedback_score = item.get('feedback', 5)  # Standardwert 5 falls kein Feedback vorhanden

        encoding = self.tokenizer(
            input_text + self.tokenizer.eos_token + output_text,
            truncation=True,
            padding="max_length",
            max_length=self.max_length,
            return_tensors="pt"
        )

        input_ids = encoding['input_ids'].squeeze()
        attention_mask = encoding['attention_mask'].squeeze()

        return {
            'input_ids': input_ids,
            'attention_mask': attention_mask,
            'labels': input_ids,
            'feedback': torch.tensor(feedback_score, dtype=torch.float)  # Feedback als zusätzlicher Faktor
        }
def fine_tune_gpt2_with_feedback():
    # Lade die Feedback-Daten
    feedback_data = load_feedback_data()

    # Erstelle das Dataset mit dem Feedback
    dataset = CustomFeedbackDataset(feedback_data, tokenizer)

    # Lade die Trainingsparameter aus der config.json
    with open("config/config.json", "r") as config_file:
        config = json.load(config_file)

    # Definiere die Trainingsparameter
    training_args = TrainingArguments(
        output_dir="./results",
        num_train_epochs=config["train_epochs"],
        per_device_train_batch_size=config["batch_size"],
        save_steps=10_000,
        save_total_limit=2,
    )

    # Erstelle den Trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=dataset,
        # Möglichkeit zur Gewichtung des Feedbacks implementieren
    )

    # Starte das Training
    trainer.train()

training.py:
import json

def training_mode(training_data_file="data/training_data.json", theme=""):
    while True:
        question = input("Gib eine Frage ein (oder 'exit' zum Beenden): ").strip()
        if question.lower() == 'exit':
            break

        if not question:
            print("Die Frage darf nicht leer sein. Versuche es erneut.")
            continue

        answer = input("Gib die richtige Antwort ein: ").strip()
        if not answer:
            print("Die Antwort darf nicht leer sein. Versuche es erneut.")
            continue

        entry = {"input": question, "output": answer}

        try:
            with open(training_data_file, "r+", encoding="utf-8") as file:
                data = json.load(file)
                data.append(entry)
                file.seek(0)
                json.dump(data, file, indent=4, ensure_ascii=False)
            print(f"Die Frage-Antwort-Paar wurde in {training_data_file} gespeichert!")

        except FileNotFoundError:
            print(f"Datei {training_data_file} nicht gefunden. Eine neue Datei wird erstellt.")
            with open(training_data_file, "w", encoding="utf-8") as file:
                json.dump([entry], file, indent=4, ensure_ascii=False)

        except json.JSONDecodeError:
            print(f"Ungültige Daten in {training_data_file}. Datei wird neu erstellt.")
            with open(training_data_file, "w", encoding="utf-8") as file:
                json.dump([entry], file, indent=4, ensure_ascii=False)

        except Exception as e:
            print(f"Fehler beim Speichern der Frage-Antwort-Paare: {e}")


main.py:
from _main.theme_manager import create_theme_directory
from training.training import training_mode
from training.buddy_mode import buddy_mode
from _main.utils import remind_user, reset_timer
import tkinter as tk
import threading

def main():
    reminder_thread = threading.Thread(target=remind_user, daemon=True)
    reminder_thread.start()
    
    print("Willkommen zum KI-Lern-Buddy!")
    
    try:
        theme = input("Wähle ein Thema oder erstelle ein neues: ").strip()
        feedback_file_path, training_file_path = create_theme_directory(theme)
        reset_timer()  
    except KeyboardInterrupt:
        print("\nProgramm wurde durch Benutzerabbruch (Strg+C) beendet.")
        exit(0)
    
    while True:
        mode = input("Wähle einen Modus ('training', 'buddy', 'exit'): ").strip().lower()
        reset_timer()  

        if mode == 'training':
            training_mode(training_file_path, theme)
        elif mode == 'buddy':
            buddy_mode(training_file_path, theme) 
        elif mode == 'exit':
            print("Auf Wiedersehen!")
            break
        else:
            print("Ungültige Eingabe. Bitte 'training', 'buddy' oder 'exit' eingeben.")
            print("Hinweis: Verwende die genauen Begriffe")

if __name__ == "__main__":
    main()
